---
title: [빅데이터] 하둡(cloudera)
author: HEECHANG
layout: post
---

# 하둡
### BIGDATA STUDY(7.08)

##Hadoop설치 및 실행

하둡이란?

분산스토리지(HDFS) + 병렬처리 프레임워크(MapReduce)

1. HDFS
HDFS에 데이터를 저장하면, 다수의 노드에 복제 데이터도 함께 저장되서 데이터 유실을 방지
HDFS에 파일을 저장하거나, 저장된 파일을 조회하려면 스트리밍 방식으로 데이터에 접근해야함
한번 저장된 데이터는 수정할 수 없고, 읽기만 가능하게 되서 데이터 무결성을 유지(append가능)
일부 노드 장애는 서비스에 영향을 주지 않음
덩어리를 복제하여 전체 클러스터에 분산 저장
저렴한 컴퓨터 병렬로 여러 개 연결, 병렬 처리 지원

2. MapReduce
컴퓨팅 노드들이 병렬로 데이터를 처리하는 프레임워크
함수형 프로그램에서 일반적으로 사용하는 Map과 Reduce라는 함수 기반으로 구성
복잡한 컴퓨팅을 Map/Reduce 두가지로 단순


스케일 아웃 - 리소스의 부족이 있더라도 간단한 추가가 가능하

Apache Hadoop, Cloudera Hadoop, Hortonworks Data Platform 등

1. rpm 다운로드 설치
2. tar.gz다운로드 설치
3. yum, apt-get 패키지 관리자 설치
4. Cloudera Manager, Ambari 하 클러스터 관리자 설치


##Hadoop 설치방법

필수 패키지 설치
```
yum -y install wget vim ftp eclipe
```

hadoop 계정, 사용자그룹 생성
```
groupadd hadoop
useradd -g hadoop -m hadoop
passwd Hadoop
(hadoop 사용자 암호 두번 입력)
```

java 설치
```
su - root
cd /home/hadoop/Downloads
chmod +x jdk-6u45-linux-x64-rpm.bin
./jdk-6u45-linux-x64-rpm.bin
cd /usr/java/
ln -s jdk1.6.0_45 jdk1.6
exit
```
설치경로
/usr/java/jdk1.6.0_45/

path추가
```
vim /home/hadoop/.bashrc

//추가
export JAVA_HOME=/usr/java/jdk1.6
export PATH=$JAVA_HOME/bin:$PATH

source /home/hadoop/.bashrc
java -version
```

**모든 VM**
필수 패키지 설치
hadoop사용자 생성
환경변수 설정
가상머신 자바설치
하둡 설치
하둡 설정
하둡 디렉토리 생성

**마스터 VM**
SSH 키등록
하둡 실행
-마스터
-슬레이브
-세컨더리 마스터
-스타트올
설치 테스트

가상머신 접속
```
ssh root@masterIP
```
가상머신에도 동일한 과정 반복

방화벽 설정 해제
```
iptables -L (확인)
iptables -F (해제)
```

환경변수 등록
```
vim /home/hadoop/.bash_profile

export JAVA_HOME=/usr/java/jdk1.6
export PATH=$JAVA_HOME/bin:/home/hadoop/hadoop/bin:$PATH
```

bash_profile : 로그인 쉘 환경 su -할때만 로드
bashrc : 로그인 이외의 쉘 환경 (터미널 창을 열때, bash 쉘에 접근할때 로드)

마스터에서 가상머신으로 파일 전송
```
scp ./jdk-6u45-linux-x64-rpm.bin root@[가상머신 ip 주소]:
(root 암호 입력)
```
이후 루트 계정에 java설치

하둡 설치
가상머신의 hadoop 계정으로 로그인 후 하둡 설치
```
ssh hadoop@[가상머신의 IP주소]
wget http://archive.apache.arg/dist/hadoop/core/hadoop-1.1.2/hadoop-1.1.2.tar.gz
tar xvzf hadoop-1.1.2.tar.gz
ln -s hadoop-1.1.2 hadoop
```

하둡 설정
/home/hadoop/hadoop/conf

hadoop-env.sh 하둡 환경설정
masters 세컨더리마스터 서버IP주소 리스트
slaves 슬레이브 서버IP주소 리스트
core-site.xml HDFS와 MapReduce공통 설정
hdfs-site.xml HDFS설정
mapred-site.xml MapReduce설정


---중간생략---

wordcounting 실습
```
cd /usr/lib/hadoop-mapreduce

ls *examples.jar

echo "Hello world in HDFS" > /home/cloudera/testfile1

echo "Haddp word count example in HDFS" > /home/cloudera/testfile2

hdfs dfs -mkdir /user/cloudera/input

hdfs dfs -put /home/cloudera/testfile1 /home/cloudera/input

hdfs dfs -put /home/cloudera/testfile2 /home/cloudera/input

hadoop jar hadoop-mapreduce-examples.jar wordcount /user/cloudera/input /user/cloudera/output

hdfs dfs -ls /user/cloudera/output
```
